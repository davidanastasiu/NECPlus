{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_norm_dataset(sensor_data0):\n",
    "    a = sensor_data0\n",
    "    b = a[:-1]\n",
    "    a = a[1:]-b\n",
    "    c = np.array([0]+a.tolist())\n",
    "    mean = c.mean()\n",
    "    print(\"mean is: \",mean)\n",
    "    std = c.std()\n",
    "    print(\"std is \",std)\n",
    "    c = (c-mean)/std\n",
    "\n",
    "    extream_num = 0\n",
    "    print(\"extream boundary is: \", std*alpha_extreams)\n",
    "    total_num = len(c)\n",
    "    for i in range(total_num):\n",
    "        if(abs(c[i])>alpha_extreams):\n",
    "            extream_num += 1\n",
    "    print(\" the total number is: \", total_num)\n",
    "    print(\" the number of extreams is: \", extream_num, \" the ratio is: \", extream_num/total_num)\n",
    "\n",
    "    return c, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_dataset(sensor_id, start_point, train_point):\n",
    "    # read sensor data to vector\n",
    "    if(str(sensor_id)[0]=='4'):\n",
    "        trainX = pd.read_csv('./data'+'/reservoir_stor_'+str(sensor_id)+'_sof24.tsv', sep='\\t')\n",
    "    elif(str(sensor_id)[0]=='6'):\n",
    "        trainX = pd.read_csv('./data'+'/raingauge_byhour_'+str(sensor_id)+'_sof.tsv', sep='\\t')\n",
    "    else:\n",
    "        print(\"Error: the support sensor type is 4***or 6****.\")\n",
    "        sys.exit()\n",
    "    start_num = trainX[trainX[\"TSC_TSTAMP_UTC\"]==start_point].index.values[0]\n",
    "    print(\"for sensor \", sensor_id,\"start_num is: \", start_num)\n",
    "    idx_num = 0\n",
    "    print(len(trainX))\n",
    "    print(trainX[:3])\n",
    "\n",
    "    #foot label of train_end\n",
    "    train_end = trainX[trainX[\"TSC_TSTAMP_UTC\"]==train_point].index.values[0] - start_num \n",
    "    print(\"train_end is : \", train_end)\n",
    "    \n",
    "    #the whole dataset to be preprocessed\n",
    "    train_x = trainX[start_num:] \n",
    "    print(len(train_x))\n",
    "    sensor_data = np.array(train_x[\"TSC_VALUE_F\"])\n",
    "    sensor_time = np.array(train_x[\"TSC_TSTAMP_UTC\"])\n",
    "    \n",
    "    \n",
    "    return trainX, sensor_data, sensor_time, start_num, train_end\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samples(start): # generate 24 points in the year start from  start_time_id\n",
    "    \n",
    "    extreme_num = 10 # at least extreme_num points have extreme values in the forecasting zone\n",
    "    extreme_total = 0\n",
    "    random_total = 0\n",
    "        \n",
    "    gen_set = []\n",
    "    r_set = []\n",
    "   \n",
    "    while((extreme_total<extreme_num) or (random_total<24-extreme_num) ):\n",
    "        \n",
    "        i = random.randint(0, ll-1)\n",
    "            \n",
    "        if i not in gen_set:\n",
    "            label = np.array(class_label[start+i:(start+i+72)])\n",
    "\n",
    "            if(label.sum()>=1 and extreme_total<extreme_num):\n",
    "                extreme_total += 1;\n",
    "                gen_set.append(i)\n",
    "                r_set.append(sensor_time[start+i])\n",
    "                print(\"Having extreme point in the seq start with: \",sensor_time[start+i])\n",
    "            elif random_total<(24-extreme_num):\n",
    "                random_total += 1;\n",
    "                gen_set.append(i)\n",
    "                r_set.append(sensor_time[start+i])\n",
    "                if label.sum()>=1 :\n",
    "                    print(\"Having extreme point in the seq start with: \",sensor_time[start+i])\n",
    "                \n",
    "    return r_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_ids = [4001]\n",
    "\n",
    "for sensor_id in sensor_ids:\n",
    "    \n",
    "    start_point = '1980-12-31 14:30:00'\n",
    "    train_end = 0 \n",
    "    train_point = '2019-12-31 14:30:00'\n",
    "    print(\"Begin!! Sensor id is :---------------------\", sensor_id)\n",
    "    alpha_extreams = 1.5 # normal/extreme boundary, \\epsilon=1.5\n",
    "    \n",
    "    trainX, sensor_data, sensor_time, start_num, train_end = read_dataset(sensor_id=sensor_id, start_point=start_point, train_point=train_point)    \n",
    "    sensor_data_norm, mean, std = diff_norm_dataset(sensor_data)\n",
    "    # 2 years for val, 2 years for test\n",
    "    val1_start_id = trainX[trainX[\"TSC_TSTAMP_UTC\"]=='2014-01-01 14:30:00'].index.values[0] - start_num      \n",
    "    val1_end_id = trainX[trainX[\"TSC_TSTAMP_UTC\"]=='2014-12-28 14:30:00'].index.values[0] - start_num  \n",
    "    val2_start_id = trainX[trainX[\"TSC_TSTAMP_UTC\"]=='2016-01-01 14:30:00'].index.values[0] - start_num      \n",
    "    val2_end_id = trainX[trainX[\"TSC_TSTAMP_UTC\"]=='2016-12-28 14:30:00'].index.values[0] - start_num \n",
    "    test1_start_id = trainX[trainX[\"TSC_TSTAMP_UTC\"]=='2017-01-01 14:30:00'].index.values[0] - start_num      \n",
    "    test1_end_id = trainX[trainX[\"TSC_TSTAMP_UTC\"]=='2017-12-28 14:30:00'].index.values[0] - start_num \n",
    "    test2_start_id = trainX[trainX[\"TSC_TSTAMP_UTC\"]=='2018-01-01 14:30:00'].index.values[0] - start_num      \n",
    "    test2_end_id = trainX[trainX[\"TSC_TSTAMP_UTC\"]=='2018-12-28 14:30:00'].index.values[0] - start_num \n",
    "    \n",
    "    ll = min(val1_end_id-val1_start_id, val2_end_id-val2_start_id, test1_end_id-test1_start_id, test2_end_id-test2_start_id)    \n",
    "\n",
    "    class_label = []\n",
    "    for i in range(len(sensor_data_norm)):\n",
    "        if abs(sensor_data_norm[i])>alpha_extreams:\n",
    "            class_label.append(1)\n",
    "        else:\n",
    "            class_label.append(0)\n",
    "            \n",
    "    val1 = gen_samples(val1_start_id)\n",
    "    val2 = gen_samples(val2_start_id)\n",
    "    test1 = gen_samples(test1_start_id)\n",
    "    test2 = gen_samples(test2_start_id)\n",
    "    \n",
    "    val = val1 + val2\n",
    "    df = pd.DataFrame(val, columns=['Hold Out Start'])  \n",
    "    df.to_csv('./data/'+str(sensor_id)+'_validation_timestamps_24avg.tsv', sep='\\t')\n",
    "    \n",
    "    test = test1 + test2\n",
    "    df = pd.DataFrame(test, columns=['Start'])  \n",
    "    df.to_csv('./data/'+str(sensor_id)+'_test_timestamps_24avg.tsv', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
